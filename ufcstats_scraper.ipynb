{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3f3dc362",
      "metadata": {},
      "source": [
        "# UFC Stats Scraper\n",
        "This notebook adapts the original `ufcstats_scraper.py` script into executable cells. Run the cells from top to bottom to build the scraper and optionally execute the crawl."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43cef2f6",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "Install the required dependencies in the active environment before running the scraper. You can either create the provided virtual environment (see `README_environment.md`) or run:\n",
        "```bash\n",
        "pip install requests requests-cache beautifulsoup4 tenacity pandas python-dateutil tqdm\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "a192e331",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import requests_cache\n",
        "from bs4 import BeautifulSoup as BS\n",
        "from dateutil import parser as dateparser\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from tqdm import tqdm\n",
        "\n",
        "BASE = \"http://ufcstats.com\"\n",
        "DATA_DIR = \"./ufc_out\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "EVENTS_CSV = os.path.join(DATA_DIR, \"events.csv\")\n",
        "FIGHTS_CSV = os.path.join(DATA_DIR, \"fights.csv\")\n",
        "FIGHTERS_CSV = os.path.join(DATA_DIR, \"fighters.csv\")\n",
        "TOT_OVERALL_CSV = os.path.join(DATA_DIR, \"fight_totals_overall.csv\")\n",
        "TOT_ROUND_CSV = os.path.join(DATA_DIR, \"fight_totals_round.csv\")\n",
        "SIG_OVERALL_CSV = os.path.join(DATA_DIR, \"fight_sig_overall.csv\")\n",
        "SIG_ROUND_CSV = os.path.join(DATA_DIR, \"fight_sig_round.csv\")\n",
        "FAIL_CSV = os.path.join(DATA_DIR, \"failures.csv\")\n",
        "STATE_JSON = os.path.join(DATA_DIR, \"state.json\")\n",
        "\n",
        "requests_cache.install_cache(os.path.join(DATA_DIR, \"http_cache\"), backend=\"sqlite\", expire_after=60 * 60 * 24 * 7)\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"UFC research (mailto:you@example.com)\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "54f7fceb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_url(u: str) -> str:\n",
        "    if not u:\n",
        "        return u\n",
        "    return u.strip()\n",
        "\n",
        "\n",
        "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=2, max=30), reraise=True)\n",
        "def _get(url: str) -> requests.Response:\n",
        "    r = requests.get(normalize_url(url), headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r\n",
        "\n",
        "\n",
        "def soup(url: str) -> BS:\n",
        "    html = _get(url).text\n",
        "    return BS(html, \"html.parser\")\n",
        "\n",
        "\n",
        "def clean(x: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", x or \"\").strip()\n",
        "\n",
        "\n",
        "def parse_height_to_inches(text):\n",
        "    m = re.search(r\"(\\d+)\\s*'\\s*(\\d+)\", text or \"\")\n",
        "    return int(m.group(1)) * 12 + int(m.group(2)) if m else None\n",
        "\n",
        "\n",
        "def parse_reach_to_inches(text):\n",
        "    m = re.search(r\"(\\d+)\\s*\\\"\", text or \"\")\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "def split_of(text):\n",
        "    m = re.search(r\"(\\d+)\\s*of\\s*(\\d+)\", text or \"\")\n",
        "    return (int(m.group(1)), int(m.group(2))) if m else (None, None)\n",
        "\n",
        "\n",
        "def parse_pct(text):\n",
        "    m = re.search(r\"(\\d+(?:\\.\\d+)?)\\s*%\", text or \"\")\n",
        "    return float(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "def parse_mmss(text):\n",
        "    m = re.search(r\"(\\d+):(\\d+)\", text or \"\")\n",
        "    return int(m.group(1)) * 60 + int(m.group(2)) if m else (0 if text and text.strip() == \"0:00\" else None)\n",
        "\n",
        "\n",
        "def years_between(dob_iso, event_iso):\n",
        "    if not dob_iso or not event_iso:\n",
        "        return None\n",
        "    try:\n",
        "        dob = date.fromisoformat(dob_iso)\n",
        "        evd = date.fromisoformat(event_iso)\n",
        "        return evd.year - dob.year - ((evd.month, evd.day) < (dob.month, dob.day))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_state():\n",
        "    if os.path.exists(STATE_JSON):\n",
        "        with open(STATE_JSON, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return {\"event_idx\": 0}\n",
        "\n",
        "\n",
        "def save_state(state):\n",
        "    with open(STATE_JSON, \"w\") as f:\n",
        "        json.dump(state, f)\n",
        "\n",
        "\n",
        "def append_df(path, df):\n",
        "    if df is None or not len(df):\n",
        "        return\n",
        "    header = not os.path.exists(path)\n",
        "    df.to_csv(path, mode=\"a\", header=header, index=False)\n",
        "\n",
        "\n",
        "def existing_ids(path, col):\n",
        "    if not os.path.exists(path):\n",
        "        return set()\n",
        "    try:\n",
        "        return set(pd.read_csv(path, usecols=[col])[col].dropna().astype(str).tolist())\n",
        "    except Exception:\n",
        "        return set()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "2b493232",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "TOTALS_COLS = {\n",
        "    \"KD\": \"kd\",\n",
        "    \"SIG. STR.\": \"sig_str\",\n",
        "    \"SIG. STR. %\": \"sig_str_pct\",\n",
        "    \"TOTAL STR.\": \"total_str\",\n",
        "    \"TD\": \"td\",\n",
        "    \"TD %\": \"td_pct\",\n",
        "    \"SUB. ATT\": \"sub_att\",\n",
        "    \"REV.\": \"rev\",\n",
        "    \"CTRL\": \"ctrl\",\n",
        "}\n",
        "\n",
        "SIG_COLS = {\n",
        "    \"SIG. STR.\": \"sig_str\",\n",
        "    \"SIG. STR. %\": \"sig_str_pct\",\n",
        "    \"HEAD\": \"head\",\n",
        "    \"BODY\": \"body\",\n",
        "    \"LEG\": \"leg\",\n",
        "    \"DISTANCE\": \"distance\",\n",
        "    \"CLINCH\": \"clinch\",\n",
        "    \"GROUND\": \"ground\",\n",
        "}\n",
        "\n",
        "\n",
        "def _normalize_headers(ths):\n",
        "    return [re.sub(r\"\\s+\", \" \", th.get_text(strip=True)).upper() for th in ths]\n",
        "\n",
        "\n",
        "def _split_cell_texts(td):\n",
        "    texts = [clean(p.get_text(\" \", strip=True)) for p in td.select(\".b-fight-details__table-text\")]\n",
        "    if not texts:\n",
        "        text = clean(td.get_text(\" \", strip=True))\n",
        "        texts = [text] if text else []\n",
        "    return [t for t in texts if t is not None]\n",
        "\n",
        "\n",
        "def _rows_from_tr(tds):\n",
        "    columns = [_split_cell_texts(td) for td in tds]\n",
        "    lengths = [len(col) for col in columns if col]\n",
        "    if not lengths:\n",
        "        return []\n",
        "    fighters = max(lengths)\n",
        "    rows = []\n",
        "    for idx in range(fighters):\n",
        "        row = []\n",
        "        for col in columns:\n",
        "            row.append(col[idx] if idx < len(col) else \"\")\n",
        "        rows.append(row)\n",
        "    return rows\n",
        "\n",
        "\n",
        "def _parse_row_values(headers, values, colmap):\n",
        "    vals = {}\n",
        "    for h, text in zip(headers, values):\n",
        "        key = colmap.get(h)\n",
        "        if not key:\n",
        "            continue\n",
        "        t = text or \"\"\n",
        "        if key in {\"sig_str\", \"total_str\", \"td\", \"head\", \"body\", \"leg\", \"distance\", \"clinch\", \"ground\"}:\n",
        "            landed, att = split_of(t)\n",
        "            vals[f\"{key}_landed\"] = landed\n",
        "            vals[f\"{key}_attempted\"] = att\n",
        "        elif key in {\"sig_str_pct\", \"td_pct\"}:\n",
        "            vals[key] = parse_pct(t)\n",
        "        elif key == \"ctrl\":\n",
        "            vals[\"ctrl_seconds\"] = parse_mmss(t)\n",
        "        elif key in {\"kd\", \"sub_att\", \"rev\"}:\n",
        "            try:\n",
        "                vals[key] = int(t) if t not in {\"--\", \"\"} else None\n",
        "            except Exception:\n",
        "                vals[key] = None\n",
        "    return vals\n",
        "\n",
        "\n",
        "def parse_table_block(table, title_text, fight_id, event_id, event_date_iso, red_id, blue_id):\n",
        "    header_section = table.find(\"thead\")\n",
        "    if not header_section:\n",
        "        return [], [], None\n",
        "    header_tr = header_section.find(\"tr\")\n",
        "    if not header_tr:\n",
        "        return [], [], None\n",
        "    headers = _normalize_headers(header_tr.find_all(\"th\", recursive=False))\n",
        "\n",
        "    if any(h in {\"HEAD\", \"BODY\", \"LEG\", \"DISTANCE\", \"CLINCH\", \"GROUND\"} for h in headers):\n",
        "        colmap = SIG_COLS\n",
        "        table_tag = \"significant\"\n",
        "    else:\n",
        "        colmap = TOTALS_COLS\n",
        "        table_tag = \"totals\"\n",
        "\n",
        "    overall_rows, per_round_rows = [], []\n",
        "    fighters = [red_id, blue_id]\n",
        "    current_round = None\n",
        "\n",
        "    children = [child for child in table.children if getattr(child, \"name\", None) in {\"thead\", \"tbody\"}]\n",
        "    for child in children:\n",
        "        if child.name == \"thead\":\n",
        "            text = clean(child.get_text(\" \", strip=True))\n",
        "            match = re.search(r\"ROUND\\s*(\\d+)\", text, re.IGNORECASE)\n",
        "            if match:\n",
        "                try:\n",
        "                    current_round = int(match.group(1))\n",
        "                except Exception:\n",
        "                    current_round = None\n",
        "            continue\n",
        "\n",
        "        if child.name != \"tbody\":\n",
        "            continue\n",
        "\n",
        "        for tr in child.find_all(\"tr\", recursive=False):\n",
        "            tds = tr.find_all(\"td\", recursive=False)\n",
        "            if not tds:\n",
        "                continue\n",
        "            row_values = _rows_from_tr(tds)\n",
        "            if not row_values:\n",
        "                continue\n",
        "\n",
        "            level = \"overall\" if current_round is None else \"round\"\n",
        "            base = {\n",
        "                \"fight_id\": fight_id,\n",
        "                \"event_id\": event_id,\n",
        "                \"event_date\": event_date_iso,\n",
        "                \"level\": level,\n",
        "                \"round\": current_round,\n",
        "                \"table\": table_tag,\n",
        "            }\n",
        "\n",
        "            for idx, values in enumerate(row_values):\n",
        "                if idx >= len(fighters):\n",
        "                    break\n",
        "                stats = _parse_row_values(headers, values, colmap)\n",
        "                if not stats:\n",
        "                    continue\n",
        "                row = {**base, \"fighter_id\": fighters[idx]}\n",
        "                row.update(stats)\n",
        "                if level == \"overall\":\n",
        "                    overall_rows.append(row)\n",
        "                else:\n",
        "                    per_round_rows.append(row)\n",
        "\n",
        "    return overall_rows, per_round_rows, table_tag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "a752ab63",
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_completed_event_urls():\n",
        "    url = f\"{BASE}/statistics/events/completed?page=all\"\n",
        "    sp = soup(url)\n",
        "    out = []\n",
        "    for a in sp.select('tr.b-statistics__table-row a[href*=\"event-details\"]'):\n",
        "        href = a.get(\"href\")\n",
        "        if href and \"event-details\" in href:\n",
        "            out.append(normalize_url(href))\n",
        "    return sorted(set(out))\n",
        "\n",
        "\n",
        "def parse_event(event_url):\n",
        "    sp = soup(event_url)\n",
        "    event_id = event_url.rsplit(\"/\", 1)[-1]\n",
        "    title = sp.select_one(\"h2.b-content__title\")\n",
        "    name = clean(title.text if title else \"\")\n",
        "    info_items = [clean(li.text) for li in sp.select(\"li.b-list__box-list-item\")]\n",
        "    date_txt = next((i.split(\":\", 1)[1].strip() for i in info_items if i.lower().startswith(\"date:\")), None)\n",
        "    location = next((i.split(\":\", 1)[1].strip() for i in info_items if i.lower().startswith(\"location:\")), None)\n",
        "    try:\n",
        "        date_iso = dateparser.parse(date_txt).date().isoformat() if date_txt else None\n",
        "    except Exception:\n",
        "        date_iso = None\n",
        "    fight_urls = sorted(\n",
        "        set(\n",
        "            normalize_url(a.get(\"href\"))\n",
        "            for a in sp.select('a[href*=\"/fight-details/\"]')\n",
        "            if a.get(\"href\")\n",
        "        )\n",
        "    )\n",
        "    row = {\n",
        "        \"event_id\": event_id,\n",
        "        \"event_url\": event_url,\n",
        "        \"name\": name,\n",
        "        \"date\": date_iso,\n",
        "        \"raw_date\": date_txt,\n",
        "        \"location\": location,\n",
        "    }\n",
        "    return row, fight_urls\n",
        "\n",
        "\n",
        "def parse_fighter(fighter_url):\n",
        "    sp = soup(fighter_url)\n",
        "    fighter_id = fighter_url.rsplit(\"/\", 1)[-1]\n",
        "    name_el = sp.select_one(\"span.b-content__title-highlight\")\n",
        "    name = clean(name_el.text if name_el else \"\")\n",
        "    bio_items = [clean(li.text) for li in sp.select(\"li.b-list__box-list-item\")]\n",
        "    h_in = r_in = stance = dob_iso = None\n",
        "    for it in bio_items:\n",
        "        upper = it.upper()\n",
        "        if upper.startswith(\"HEIGHT:\"):\n",
        "            h_in = parse_height_to_inches(it.split(\":\", 1)[1])\n",
        "        elif upper.startswith(\"REACH:\"):\n",
        "            r_in = parse_reach_to_inches(it.split(\":\", 1)[1])\n",
        "        elif \"STANCE\" in upper:\n",
        "            stance = clean(it.split(\":\", 1)[1])\n",
        "        elif upper.startswith(\"DOB:\"):\n",
        "            try:\n",
        "                dob_iso = dateparser.parse(it.split(\":\", 1)[1]).date().isoformat()\n",
        "            except Exception:\n",
        "                pass\n",
        "    return {\n",
        "        \"fighter_id\": fighter_id,\n",
        "        \"name\": name,\n",
        "        \"height_in\": h_in,\n",
        "        \"reach_in\": r_in,\n",
        "        \"stance\": stance,\n",
        "        \"dob\": dob_iso,\n",
        "    }\n",
        "\n",
        "\n",
        "def parse_fight(fight_url, event_id=None, event_date_iso=None):\n",
        "    sp = soup(fight_url)\n",
        "    fight_id = fight_url.rsplit(\"/\", 1)[-1]\n",
        "\n",
        "    persons = sp.select(\"div.b-fight-details__person\")\n",
        "\n",
        "    def side(div):\n",
        "        a = div.select_one(\"a.b-link.b-fight-details__person-link\")\n",
        "        name = clean(a.text if a else \"\")\n",
        "        link = normalize_url(a.get(\"href\")) if a else None\n",
        "        fid = link.rsplit(\"/\", 1)[-1] if link else None\n",
        "        status_el = div.select_one(\"i.b-fight-details__person-status\")\n",
        "        status = clean(status_el.text if status_el else \"\")\n",
        "        return {\"fighter_id\": fid, \"fighter_url\": link, \"name\": name, \"status\": status}\n",
        "\n",
        "    sides = [side(p) for p in persons[:2]]\n",
        "    red = sides[0] if len(sides) >= 1 else None\n",
        "    blue = sides[1] if len(sides) >= 2 else None\n",
        "    red_id = red[\"fighter_id\"] if red else None\n",
        "    blue_id = blue[\"fighter_id\"] if blue else None\n",
        "\n",
        "\n",
        "    meta_lookup = {}\n",
        "    for block in sp.select('[class*=\"b-fight-details__text-item\"]'):\n",
        "        label_el = block.select_one('.b-fight-details__label')\n",
        "        if not label_el:\n",
        "            continue\n",
        "        label_text = clean(label_el.get_text(\" \", strip=True)).rstrip(':').lower()\n",
        "        if not label_text:\n",
        "            continue\n",
        "        label_el.extract()\n",
        "        value_text = clean(block.get_text(\" \", strip=True))\n",
        "        if not value_text:\n",
        "            continue\n",
        "        meta_lookup[label_text] = value_text\n",
        "\n",
        "    for selector in (\n",
        "        \"p.b-fight-details__text-item\",\n",
        "        \"i.b-fight-details__text-item\",\n",
        "        \"span.b-fight-details__text-item\",\n",
        "    ):\n",
        "        for node in sp.select(selector):\n",
        "            text = clean(node.get_text(\" \", strip=True))\n",
        "            if not text or ':' not in text:\n",
        "                continue\n",
        "            label, value = text.split(':', 1)\n",
        "            label_key = label.strip().lower()\n",
        "            if label_key in meta_lookup:\n",
        "                continue\n",
        "            meta_lookup[label_key] = value.strip()\n",
        "\n",
        "    method = meta_lookup.get('method')\n",
        "    referee = meta_lookup.get('referee')\n",
        "\n",
        "    end_round = None\n",
        "    round_text = meta_lookup.get('round')\n",
        "    if round_text:\n",
        "        m_round = re.search(r\"\\d+\", round_text)\n",
        "        if m_round:\n",
        "            try:\n",
        "                end_round = int(m_round.group(0))\n",
        "            except Exception:\n",
        "                end_round = None\n",
        "\n",
        "    end_time = meta_lookup.get('time')\n",
        "\n",
        "    totals_overall, totals_rounds, sig_overall, sig_rounds = [], [], [], []\n",
        "    seen_tables = set()\n",
        "    for tbl in sp.select(\"section.b-fight-details__section table\"):\n",
        "        if id(tbl) in seen_tables:\n",
        "            continue\n",
        "        seen_tables.add(id(tbl))\n",
        "        title_el = tbl.find_previous(\"h2\")\n",
        "        title_text = title_el.get_text(\" \", strip=True) if title_el else \"\"\n",
        "        ov, pr, table_tag = parse_table_block(\n",
        "            tbl,\n",
        "            title_text,\n",
        "            fight_id,\n",
        "            event_id,\n",
        "            event_date_iso,\n",
        "            red_id,\n",
        "            blue_id,\n",
        "        )\n",
        "        if not ov and not pr:\n",
        "            continue\n",
        "\n",
        "        if table_tag == \"totals\":\n",
        "            totals_overall.extend(ov)\n",
        "            totals_rounds.extend(pr)\n",
        "        elif table_tag == \"significant\":\n",
        "            sig_overall.extend(ov)\n",
        "            sig_rounds.extend(pr)\n",
        "        elif \"TOTAL\" in (title_text or \"\").upper():\n",
        "            totals_overall.extend(ov)\n",
        "            totals_rounds.extend(pr)\n",
        "        elif \"SIGNIFICANT\" in (title_text or \"\").upper():\n",
        "            sig_overall.extend(ov)\n",
        "            sig_rounds.extend(pr)\n",
        "\n",
        "    fight_row = {\n",
        "        \"fight_id\": fight_id,\n",
        "        \"fight_url\": fight_url,\n",
        "        \"event_id\": event_id,\n",
        "        \"event_date\": event_date_iso,\n",
        "        \"red_id\": red_id,\n",
        "        \"red_name\": red[\"name\"] if red else None,\n",
        "        \"red_result\": red[\"status\"] if red else None,\n",
        "        \"blue_id\": blue_id,\n",
        "        \"blue_name\": blue[\"name\"] if blue else None,\n",
        "        \"blue_result\": blue[\"status\"] if blue else None,\n",
        "        \"method\": method,\n",
        "        \"referee\": referee,\n",
        "        \"end_round\": end_round,\n",
        "        \"end_time\": end_time,\n",
        "    }\n",
        "    return fight_row, sides, totals_overall, totals_rounds, sig_overall, sig_rounds\n",
        "\n",
        "\n",
        "def crawl():\n",
        "    state = load_state()\n",
        "    event_urls = list_completed_event_urls()\n",
        "\n",
        "    done_events = existing_ids(EVENTS_CSV, \"event_id\")\n",
        "    done_fights = existing_ids(FIGHTS_CSV, \"fight_id\")\n",
        "    have_fighter = existing_ids(FIGHTERS_CSV, \"fighter_id\")\n",
        "\n",
        "    print(f\"Found {len(event_urls)} events. Resuming from event index {state['event_idx']}.\")\n",
        "\n",
        "    for ei in tqdm(range(state[\"event_idx\"], len(event_urls)), desc=\"Events\"):\n",
        "        print(f\"Processing event {ei} of {len(event_urls)}\")\n",
        "        eurl = event_urls[ei]\n",
        "        try:\n",
        "            ev_row, fight_urls = parse_event(eurl)\n",
        "        except Exception as exc:\n",
        "            append_df(\n",
        "                FAIL_CSV,\n",
        "                pd.DataFrame([\n",
        "                    {\"url\": eurl, \"type\": \"event\", \"error\": str(exc)}\n",
        "                ]),\n",
        "            )\n",
        "            state[\"event_idx\"] = ei + 1\n",
        "            save_state(state)\n",
        "            continue\n",
        "\n",
        "        if ev_row[\"event_id\"] not in done_events:\n",
        "            append_df(EVENTS_CSV, pd.DataFrame([ev_row]))\n",
        "            done_events.add(ev_row[\"event_id\"])\n",
        "\n",
        "        fights_batch = []\n",
        "        fighters_batch = []\n",
        "        failures_batch = []\n",
        "        tot_overall_batch, tot_round_batch = [], []\n",
        "        sig_overall_batch, sig_round_batch = [], []\n",
        "\n",
        "        for furl in tqdm(fight_urls, leave=False, desc=f\"Fights@{ev_row['event_id']}\"):\n",
        "            fid = furl.rsplit(\"/\", 1)[-1]\n",
        "            if fid in done_fights:\n",
        "                continue\n",
        "            try:\n",
        "                fight_row, sides, t_overall, t_rounds, s_overall, s_rounds = parse_fight(\n",
        "                    furl,\n",
        "                    event_id=ev_row[\"event_id\"],\n",
        "                    event_date_iso=ev_row[\"date\"],\n",
        "                )\n",
        "                fights_batch.append(fight_row)\n",
        "                tot_overall_batch.extend(t_overall)\n",
        "                tot_round_batch.extend(t_rounds)\n",
        "                sig_overall_batch.extend(s_overall)\n",
        "                sig_round_batch.extend(s_rounds)\n",
        "\n",
        "                for s in sides:\n",
        "                    if not s or not s.get(\"fighter_id\") or s[\"fighter_id\"] in have_fighter:\n",
        "                        continue\n",
        "                    try:\n",
        "                        bio = parse_fighter(s[\"fighter_url\"])\n",
        "                        bio[\"age_on_event\"] = years_between(bio.get(\"dob\"), ev_row[\"date\"])\n",
        "                        fighters_batch.append(bio)\n",
        "                        have_fighter.add(bio[\"fighter_id\"])\n",
        "                        time.sleep(0.1)\n",
        "                    except Exception as fighter_exc:\n",
        "                        failures_batch.append(\n",
        "                            {\n",
        "                                \"url\": s[\"fighter_url\"],\n",
        "                                \"type\": \"fighter\",\n",
        "                                \"error\": str(fighter_exc),\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "                done_fights.add(fid)\n",
        "\n",
        "                if len(fights_batch) >= 20:\n",
        "                    append_df(FIGHTS_CSV, pd.DataFrame(fights_batch))\n",
        "                    fights_batch.clear()\n",
        "                if len(fighters_batch) >= 20:\n",
        "                    append_df(FIGHTERS_CSV, pd.DataFrame(fighters_batch))\n",
        "                    fighters_batch.clear()\n",
        "                if len(tot_overall_batch) >= 50:\n",
        "                    append_df(TOT_OVERALL_CSV, pd.DataFrame(tot_overall_batch))\n",
        "                    tot_overall_batch.clear()\n",
        "                if len(tot_round_batch) >= 50:\n",
        "                    append_df(TOT_ROUND_CSV, pd.DataFrame(tot_round_batch))\n",
        "                    tot_round_batch.clear()\n",
        "                if len(sig_overall_batch) >= 50:\n",
        "                    append_df(SIG_OVERALL_CSV, pd.DataFrame(sig_overall_batch))\n",
        "                    sig_overall_batch.clear()\n",
        "                if len(sig_round_batch) >= 50:\n",
        "                    append_df(SIG_ROUND_CSV, pd.DataFrame(sig_round_batch))\n",
        "                    sig_round_batch.clear()\n",
        "                if len(failures_batch) >= 10:\n",
        "                    append_df(FAIL_CSV, pd.DataFrame(failures_batch))\n",
        "                    failures_batch.clear()\n",
        "\n",
        "                time.sleep(0.1)\n",
        "            except Exception as fight_exc:\n",
        "                failures_batch.append(\n",
        "                    {\"url\": furl, \"type\": \"fight\", \"error\": str(fight_exc)}\n",
        "                )\n",
        "\n",
        "        append_df(FIGHTS_CSV, pd.DataFrame(fights_batch))\n",
        "        fights_batch.clear()\n",
        "        append_df(FIGHTERS_CSV, pd.DataFrame(fighters_batch))\n",
        "        fighters_batch.clear()\n",
        "        append_df(TOT_OVERALL_CSV, pd.DataFrame(tot_overall_batch))\n",
        "        tot_overall_batch.clear()\n",
        "        append_df(TOT_ROUND_CSV, pd.DataFrame(tot_round_batch))\n",
        "        tot_round_batch.clear()\n",
        "        append_df(SIG_OVERALL_CSV, pd.DataFrame(sig_overall_batch))\n",
        "        sig_overall_batch.clear()\n",
        "        append_df(SIG_ROUND_CSV, pd.DataFrame(sig_round_batch))\n",
        "        sig_round_batch.clear()\n",
        "        append_df(FAIL_CSV, pd.DataFrame(failures_batch))\n",
        "        failures_batch.clear()\n",
        "\n",
        "        state[\"event_idx\"] = ei + 1\n",
        "        save_state(state)\n",
        "        time.sleep(2.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "c0d9ec3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 747 events. Resuming from event index 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   0%|          | 0/742 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 5 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   0%|          | 1/742 [00:17<3:39:57, 17.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 6 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   0%|          | 2/742 [00:29<2:57:08, 14.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 7 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   0%|          | 3/742 [00:49<3:29:35, 17.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 8 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 4/742 [01:07<3:30:51, 17.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 9 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 5/742 [01:20<3:11:05, 15.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 10 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 6/742 [01:37<3:17:05, 16.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 11 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 7/742 [01:55<3:25:42, 16.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 12 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 8/742 [02:10<3:19:43, 16.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 13 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 9/742 [02:27<3:19:58, 16.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing event 14 of 747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Events:   1%|          | 9/742 [02:34<3:30:19, 17.22s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the crawler (uncomment to execute; expect a long-running job)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 246\u001b[39m, in \u001b[36mcrawl\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     bio = \u001b[43mparse_fighter\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfighter_url\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     bio[\u001b[33m\"\u001b[39m\u001b[33mage_on_event\u001b[39m\u001b[33m\"\u001b[39m] = years_between(bio.get(\u001b[33m\"\u001b[39m\u001b[33mdob\u001b[39m\u001b[33m\"\u001b[39m), ev_row[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    248\u001b[39m     fighters_batch.append(bio)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mparse_fighter\u001b[39m\u001b[34m(fighter_url)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_fighter\u001b[39m(fighter_url):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     sp = \u001b[43msoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfighter_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     fighter_id = fighter_url.rsplit(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m     45\u001b[39m     name_el = sp.select_one(\u001b[33m\"\u001b[39m\u001b[33mspan.b-content__title-highlight\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36msoup\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msoup\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m) -> BS:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     html = \u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m.text\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BS(html, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36m_get\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@retry\u001b[39m(stop=stop_after_attempt(\u001b[32m5\u001b[39m), wait=wait_exponential(multiplier=\u001b[32m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m=\u001b[32m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m=\u001b[32m30\u001b[39m), reraise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m) -> requests.Response:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalize_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     r.raise_for_status()\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests_cache/session.py:183\u001b[39m, in \u001b[36mCacheMixin.request\u001b[39m\u001b[34m(self, method, url, headers, expire_after, only_if_cached, refresh, force_refresh, *args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m headers = set_request_headers(headers, expire_after, only_if_cached, refresh, force_refresh)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch_form_boundary() \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mfiles\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests_cache/session.py:230\u001b[39m, in \u001b[36mCacheMixin.send\u001b[39m\u001b[34m(self, request, expire_after, only_if_cached, refresh, force_refresh, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._resend(request, actions, cached_response, **kwargs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m actions.send_request:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_and_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m     response = cached_response  \u001b[38;5;66;03m# type: ignore  # Guaranteed to be non-None by this point\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests_cache/session.py:254\u001b[39m, in \u001b[36mCacheMixin._send_and_cache\u001b[39m\u001b[34m(self, request, actions, cached_response, **kwargs)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a request and cache the response, unless disabled by settings or headers.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03mIf applicable, also handle conditional requests.\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m request = actions.update_request(request)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m actions.update_from_response(response)\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions.skip_write:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/UFCPredictor/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Run the crawler (uncomment to execute; expect a long-running job)\n",
        "crawl()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b93d6c1a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
